\chapter{Background and Motivation}
\label{chap:introduction}
    \section{Virial Coefficients}
    \label{sec:chap1VirialCoefficients}
        The virial equation of state, given as:
        \begin{equation}
          \frac{p}{\rho k_\text{B}T} = 1 + B_2(T) \rho + B_3(T) \rho^2 + \ldots,
        \end{equation}
        expresses the pressure $p$ as a power series in the number density $\rho$ of the system; $T$ is the temperature and $k_\text{B}$ is the Boltzmann constant. Through this formula, the temperature-dependent virial coefficients, $B_n(T)$, can be used to estimate a variety of physical properties in addition to the pressure, such as the Joule-Thomson coefficient,  critical properties, and others. The unique feature of the virial equation of state, in comparison to other thermodynamic models, is that it represents rigorously the effect of interactions among $N$ molecules, such that if given a molecular model, the virial coefficients for its equation of state can be determined without approximation. This can be clearly seen from the analytic expressions for the virial coefficients in terms of $N$-body configurational integrals \cite{Tester} which depend only on the interaction potential between $N$ molecules as:
        \begin{equation}\label{eq: bn}
            \begin{aligned}
                B_2(T) &= - \frac{1}{2! {V}}  \Big[ Z_2^* - Z_1^{*2} \Big]\\
                B_3(T) &= - \frac{1}{3! {V}^2}  \Big[ {V}  \big( Z_3^* - 3  Z_2^*  Z_1^* + 2  Z_1^{*3} \big) - 3  {\big( Z_2^* - Z_1^{*2} \big)}^2 \Big]
            \end{aligned}
        \end{equation}
        where, $ Z_N^* \equiv N!  {\Big( \displaystyle\frac{{V}}{Q_1} \Big)}^N  Q_N ;$ is the $N$-body configurational integral, $Q_N$ is the $N$-body canonical partition function, and ${V}$ is the volume.

        The $N$-body configurational integral, which depends on the $N$-body interaction potential, becomes exponentially more difficult to compute with increasing $N$ (where the number of configurational integrals to be computed is: 1 for B$_3$, 3 for B$_4$, 10 for B$_5$, 56 for B$_6$, 468 for B$_7$, 7123 for B$_8$, 194066 for B$_9$ \cite{ShaulPhD,Masters2008,Labik2005}). For extremely simple interaction potentials like hard spheres, up to fourth virial coefficients may be calculated analytically \cite{Masters2008}. Higher order virial coefficients using more complicated interaction potentials need to be evaluated numerically through quadrature or by using Monte Carlo (MC) simulations. Upon further simplification and assuming pairwise additivity of the potential, we can rewrite Eq.\eqref{eq: bn} using Mayer $f$-functions as \cite{Masters2008,Hansen}
        \begin{equation} \label{eq: mayerfn}
            \begin{aligned}
                B_2(T) &= -\frac{1}{2} \displaystyle\int d1 ~ f(0,1)\\
                B_3(T) &= -\frac{1}{3} \displaystyle\int \int d1~d2~f(0,1)~f(0,2)~f(1,2)
            \end{aligned}
        \end{equation}
        where $f(0,1) = \Big( \exp \big[ -\beta U_2(\mbf{r}) \big] - 1 \Big) $ and indices `1' and `2' denote the position and orientational degrees of freedom of molecules 1 and 2, respectively, with respect to molecule `0' at the origin.

        Virial coefficients can be evaluated in two ways: a) computationally, using numerical methods to evaluate the configuration integrals given an input interaction potential, and b) experimentally, typically by collecting pressure-density data and regressing its behavior at the $\rho \to 0$ limit. By comparing the values determined using the above two methods, different models of the interaction potential between $N$ molecules can be ranked for their physical accuracy.

        Empirical potentials are fit to experimental data over a broad range of conditions, and therefore they tend to describe the interaction potential as the net result of a variety of physical phenomena taking place simultaneously (including, for example, multibody interactions and nuclear quantum effects). The way that these phenomena combine to give an effective potential will depend on the state condition as well as the experimental properties being fit. Consequently, unless fit directly to them, empirical potentials often perform poorly in comparison to experimental virial coefficients \cite{Benjamin2007}, which depend purely on the interaction of a specific number of molecules.

        On the other hand, \abinitio{} potentials involve solving the \Schrodinger{} equation by using different basis functions and levels of theory and often can yield far more accurate interaction potentials as a result. Large computational resources are required to obtain coefficient with a useful level of accuracy, so the application of \abinitio{} method in this respect has been limited to low-order coefficients for small molecules. However, steady progress is being made \cite{Boothroyd2003,Hodges2004,Garberoglio2012,Shaul2012,Garberoglio2013,Hellmann2013,Garberoglio2014,Garberoglio2014mix,Hellmann2014,Schultz2015,Tat2015}. Almost all \abinitio{} potentials involve at the heart of their development, solving the electronic \Schrodinger{} equation using the Born-Oppenheimer approximation. Under this approximation, the kinetic energy of the nucleus is considered negligible when compared to the electrons, and therefore all the nuclei are assumed to be fixed at certain locations when solving the electronic structure. For the purpose of calculating really virial accurate coefficients using \abinitio{} potentials, one needs to account for nuclear quantum effects explicitly, especially at low temperatures or for light atoms, such as hydrogen. Based on the above, virial coefficients can be classified into the following three categories:

        \begin{description}
            \item[Classical virial coefficients] \hfill \\
                The virial coefficients that are calculated from an input interaction potential (empirical or \abinitio{} PES) without modification.
            \item[Semi-classical virial coefficients] \hfill \\
                The virial coefficients that are calculated using an effective potential such as the Quadratic Feynman-Hibbs (QFH) \cite{Feynman} that includes a quantum correction.
            \item[Quantum virial coefficients] \hfill \\
                The virial coefficients that are calculated using an empirical potential (quantum) or \abinitio{} PES (fully quantum) while explicitly including nuclear quantum effects.
        \end{description}
    \section{\Abinitio{} Potentials}
        In this section, different quantum chemistry methods and theories that are used in the development of the \abinitio{} \PESs{} are briefly mentioned. This digression will help develop an idea of the amount of computational effort involved in such calculations, which will later be called upon to serve as motivation for developing efficient algorithms in Chapter \ref{sec:novel algorithms}. Majority of what follows in this section is directly adapted from Chapters 4, 6 and 7 of Cramer's book \cite{Cramer} (where the interested reader may also find more comprehensive and mathematically detailed explanations) and are only intended as a precursor to better understanding the rest of this dissertation work. \\
        \subsection{From \Schrodinger{} Equation to Molecular Orbitals}
            We begin by considering the \Schrodinger{} equation and the Hamiltonian operator, $H$ of a generic atom:
            \begin{equation}\label{eq:Schrodinger}
                \begin{aligned}
                    H~\Psi &= E~\Psi \\
                    H &= T_e + T_N + V_{ee} + V_{eN} + V_{NN}
                \end{aligned}
            \end{equation}
            where $T$ and $V$ represent the kinetic and potential energy operators respectively; the subscripts $e$ and $N$ denote the electron and the nucleus respectively.

            The eigenfunctions of Eq. \eqref{eq:Schrodinger} are known as the wavefunctions of the atom and are denoted as $\Psi_i$. For ease of explanation, we consider only wavefunctions that are orthonormal, i.e., they satisfy the following the condition:
            \begin{equation}\label{eq:orthonormality}
                \int \Psi_i\, \Psi_j\, d\, \mbf{r} = \delta_{ij}
            \end{equation}
            where $\delta_{ij}$ is the Kronecker delta.

            Given a complete set of orthonormal wavefunctions, it is then possible to compute the expectation value of any physical property $A$, by expressing it in operator form $\hat{A}$, and evaluating:
            \begin{equation}\label{eq:expectation value}
                <\,A\,>\, =\, < \,\Psi_i\,|\,\hat{A}\,|\, \Psi_j\,>
            \end{equation}
            Knowing the wavefunction of a system exactly is therefore equivalent to possessing all information required about the system. Assuming we are given a complete set of orthonormal wavefunctions, we can express any generic wavefunction as a linear combination of the given set. It can be easily shown that resulting energy of such generic wavefunctions is dependent on the linear combination coefficients and the energy eigenvalues corresponding to each wavefunction in the orthonormal set. Since this set of energy eigenvalues will always have a lower bound, the variational principle allows us to rank different starting sets of wavefunctions and their corresponding coefficients based on their resulting energies w.r.t this ground state energy. According to the variational principle, the lower the resulting energy, the better the starting set of wavefunctions. Therefore one can, in principle, devise a mechanism to construct and find the best possible set of wavefunctions using various mathematical tools.

            The \Schrodinger{} equation is inherently complicated due to the correlation of interactions of many particles with one another, as expressed in Eq. \eqref{eq:Schrodinger}. However, there are certain approximations and assumptions that reduce the complexity of the equation. For instance, the Born-Oppenheimer(BO) approximation assumes that under ambient conditions, the motion of the nuclei are much slower compared to that of the electrons, owing to heavier masses. This makes it possible to separate the electronic and nuclear motions within the Hamiltonian $H$ (Eq. \eqref{eq:Schrodinger}) by setting $T_N \to 0$ and $V_N$ to some constant value. Whereas previously $H$ was dependent on the nuclear coordinates and electronic coordinates explicitly, using the BO approximation $H_{BO}$ depends explicitly only on electronic coordinates and the nuclear coordinates become parameters:
            \begin{equation}\label{eq:BO approximation}
                \begin{aligned}
                    (H_{BO} + V_N)~\Psi_{el} (\mbf{q}_i;\mbf{q}_k) &= E_{BO} \Psi_{el} (\mbf{q}_i;\mbf{q}_k)\\
                    H_{BO} &= T_e + V_{eN} + V_{ee}
                \end{aligned}
            \end{equation}

            Both the variational principle and the BO approximation have profound implications in quantum chemistry. Without the variational principle, it would not be possible to check and improve the mechanism of construction of orthonormal sets of wavefunctions. The PES, defined as $E_{BO}$ for different nuclear configurations ($\mbf{q}_k$), would not exist if it were not for the BO approximation. Although the BO approximation significantly simplifies the \Schrodinger{} equation, the complexity due to the number of particles is still a challenge.

            The concept of constructing the set of orthonormal wavefunctions for many particle systems needs a starting point. Using the BO approximation for a system like the hydrogen atom with just one electron and one nucleus, analytic solutions can be obtained for the orthonormal set of wavefunctions or Atomic Orbitals(AOs). These then, become the perfect starting point for more complicated wavefunctions (called Molecular Orbitals(MOs)) by using what is known as the Linear Combination of Atomic Orbitals(LCAO) basis set approach. Within this approach, we use AOs as basis sets and construct linear combinations of them with different weights to give rise to MO wavefunction for many electron systems. Naturally, the more the number of basis functions in the basis set, the better the description of the resulting MO.

            Starting with $N$ wavefunctions $\{\psi_1, \psi_2, \ldots \psi_N\}$ as our basis set, we seek coefficients $a_{i}$ which will yield the minimum energy for the resulting MO wavefunction $\Psi = \displaystyle\sum_{i=1}^N a_{i} \psi_i$. The following is the procedure to obtain the MO wavefunction :
            \begin{enumerate}
                \item Determine all $N^2$ values of $H_{ij}$ and $S_{ij}$ which are also known as the 'resonance integral' and 'overlap integral' respectively.
                    \begin{equation}\label{eq:resonance and overlap}
                        \begin{aligned}
                            H_{ij} &= \displaystyle\int \psi_i\, H \,\psi_j\, d\,\mbf{r}\\
                            S_{ij} &= \displaystyle\int \psi_i\, \psi_j\, d\,\mbf{r}
                        \end{aligned}
                    \end{equation}
                    Note that in practice, one would compute the values of the matrix elements $H_{ij}$ from experimental data such as the ionization energy and rotational barriers. Also, we have assumed that the MOs do not depend on the number of electrons present in the AOs that form part of the basis set. Therefore, one might be tempted to say that the LCAO approach ignores the electron-electron repulsion. However, since we are deriving the matrix elements from experimental measurements, one might think of it as implicitly including the inter-electronic repulsion, albeit in a crude sense.
                \item Determine the $N$ roots $E_j$ of the secular equation given by:
                    \begin{equation}\label{eq:secular}
                        \begin{vmatrix}
                            H_{11} - E S_{11} & H_{12} - E S_{12} & \ldots & H_{1N} - E S_{1N}\\
                            H_{21} - E S_{21} & H_{22} - E S_{22} & \ldots & H_{2N} - E S_{2N}\\
                            \vdots & \vdots & \ddots & \vdots\\
                            H_{N1} - E S_{N1} & H_{N2} - E S_{N2} & \ldots & H_{NN} - E S_{NN}
                        \end{vmatrix}
                        = 0
                    \end{equation}
                \item For each of the $N$ values of $E_j$, solve the set of linear equations:
                    \begin{equation}\label{eq:linear}
                        \displaystyle\sum_{i=1}^N a_i (H_{ki} - E S_{ki}) = 0 \:\:\:\:\: \forall k
                    \end{equation}
            \end{enumerate}
            Thus, we would obtain $N$ MOs among which there would be one that corresponds to the lowest energy which we would call the ground state MO. Note that we have implicitly assumed that energy value for the MO is simply obtained as the sum of the energies of the one-electron occupied orbitals.

            Upon careful observation of the one-electron Hamiltonian, Hartree noticed that if we set the term $V_{ee} \to 0$ in Eq. \eqref{eq:BO approximation}, we could write down the following:
            \begin{subequations}
                \begin{align}
                    \begin{split}
                        H &= \displaystyle\sum_i^N h_i\\
                        h_i &= -\frac{1}{2} \nabla^2_i - \frac{Z_k}{r_{ik}} \label{eq:one electron H}\\
                    \end{split}\\
                    h_i\,\psi_i\, &= \varepsilon_i \, \psi_i \label{eq:one electron SE}
                \end{align}
            \end{subequations}
            where $\psi_i$ are the one-electron wavefunctions and $\varepsilon_i$ are the corresponding eigenvalues.

            Since the overall Hamiltonian of Eq. \eqref{eq:BO approximation} is separable into one-electron Hamiltonians of Eq. \eqref{eq:one electron H}, the many electron wavefunction can simply be expressed as product of the one electron wavefunctions i.e., $\Psi_{HP} = \psi_1 \psi_2 \ldots \psi_N$. In order to minimize the energy given by $<\,\Psi_{HP}\, | H |\,\Psi_{HP}\,>$, it can be shown from variational calculus that each $\psi_i$ is an eigenfunction of its own operator defined as:
            \begin{equation}\label{eq:correct Hamiltonian}
                \begin{aligned}
                    h_i &= -\frac{1}{2} \nabla^2_i - \frac{Z_k}{r_{ik}} + V_i \{j\}\\
                    V_i \{j\} &= \displaystyle\sum_{j \ne i} \int \frac{\rho_j}{r_{ij}} d\,\mbf{r}
                \end{aligned}
            \end{equation}
            where $V_i \{j\}$ represents the interaction potential with all the other electrons occupying orbitals $\{j\}$ and $\rho_j = |\psi_j|^2$; is the charge density associated with electron $j$.

            From Eq. \eqref{eq:correct Hamiltonian} it can be easily seen that $\psi_j$ is needed as input to obtain the correct Hamiltonian which would ultimately result in the correct wavefunction. Therefore this posed a problem of computing a quantity that required itself as an input. Hartree proposed an iterative Self Consistent Field(SCF) method as a solution to this problem. At the first step of this method, we guess the values of all $\psi_j$ and use them to construct the correct Hamiltonian operators as per Eq. \eqref{eq:correct Hamiltonian}. Using these operators, the one-electron \Schrodinger{} equation (Eq. \eqref{eq:one electron SE}) is solved multiple times to obtain a new guess for all $\psi_j$. The process is then repeated until the results have converged based on some threshold value for the electronic energy.

            To avoid doubly counting the electronic repulsion, the energy is not computed directly as the eigenvalue but rather using the following:
            \begin{equation}\label{eq:Hartree Hamiltonian energy}
                E = \displaystyle\sum_i \varepsilon_i - \frac{1}{2} \sum_{i \ne j} \int \int |\psi_i|^2 \frac{1}{r_{ij}} |\psi_j|^2 d\,\mbf{r}_i\, d\,\mbf{r}_j
            \end{equation}

            Since Hartree product wavefunctions violated the property of indistinguishability of quantum particles and also ignored quantum mechanical exchange, a correlation effect unique to electrons of the same spin, Slater determinants provided an alternative route to incorporate these effects in the wavefunctions. By construction, Slater determinants accounted for the anti-symmetry and electronic spin (and hence exchange) which was crucial to MO wavefunctions. Expressed in determinant form as:
            \begin{equation}\label{eq:Slater determinant}
                \Psi_{SD} = \frac{1}{\sqrt{N!}}
                \begin{vmatrix}
                    \chi_1 (1) & \chi_2 (1) & \ldots & \chi_N (1)\\
                    \chi_1 (2) & \chi_2 (2) & \ldots & \chi_N (2)\\
                    \vdots & \vdots & \ddots & \vdots\\
                    \chi_1 (N) & \chi_2 (N) & \ldots & \chi_N (N)\\
                \end{vmatrix}
            \end{equation}
            where $N$ is the total number of electrons and $\chi$ is a spin-orbital, i.e., a product of the spatial orbital and an electron spin eigenfunction.

            Fock first proposed to extend the Hartree SCF method for Slater determinant wavefunctions giving rise to Slater Type Orbitals (STOs) and the Hartree-Fock(HF) SCF method to which Roothaan \cite{Roothaan1951} made valuable contributions later. The 'restricted Hartree-Fock' (RHF) formalism with closed-shell systems and wavefunctions represented as a single Slater determinant is the typical form of the HF SCF method. The procedure to be followed using this approach is outlined below:
            \begin{enumerate}
                \item Choose a basis set and a molecular geometry
                \item Guess the initial density matrix $\mbf{P}^{(0)}$ whose elements are given as:
                    \begin{equation}\label{eq:density matrix elements}
                        P_{\lambda \sigma} = 2 \displaystyle\sum_i^{occupied MO} a_{\lambda i} a_{\sigma i}
                    \end{equation}
                    where the coefficients $a_{\zeta i}$ specify the contribution of basis function $\zeta$ to the MO $i$ and the factor of two appears because with RHF theory we are considering only singlet wavefunctions in which all orbitals are doubly occupied.
                \item Construct and solve the HF secular equation which uses the Fock operator matrix elements in place of the Hamiltonian operator matrix elements in Eq. \eqref{eq:secular} as:
                    \begin{equation}\label{eq:one electron Fock matrix elements}
                        \begin{aligned}
                            f_i &= -\frac{1}{2} \nabla^2_i - \displaystyle\sum_k^{nuclei} \frac{Z_k}{r_{ik}} + V_i^{HF} \{j\}\\
                            V_i^{HF} \{j\} &= 2 J_i - K_i\\
                            F_{\mu \nu} &= \left< \mu \,\left| -\frac{1}{2} \nabla^2 \right|\,\nu \right> - \displaystyle\sum_k^{nuclei} Z_k \left< \mu \,\left| \frac{1}{r_k} \right| \, \nu \right> + \displaystyle\sum_{\lambda \sigma} P_{\lambda \sigma} \left[ (\mu \nu | \lambda \sigma) - \frac{1}{2} (\mu \lambda | \nu \sigma) \right]\\
                            (\mu \nu | \lambda \sigma) &= \displaystyle\int \int \phi_\mu (1) \phi_\nu(1) \frac{1}{r_{12}}\phi_\lambda (2) \phi_\sigma (2) d\,\mbf{r}(1)\,d\,\mbf{r}(2)
                        \end{aligned}
                    \end{equation}
                    where $\phi_\mu$ and $\phi_\nu$ represent the probability density of one electron and $\phi_\lambda$ and $\phi_\sigma$ the other; the integrals $(\mu \nu | \lambda \sigma)$ are also known as the 'four index integrals'; $J_i$ and $K_i$ are operators defined to compute $J_{ij}$ and $K_{ij}$ that are called the Coulomb and exchange integrals respectively. The exchange integrals are preceded by a factor of 1/2 because they are limited to electrons of the same spin while Coulomb interactions are present in any combination of spins. The Coulomb and exchange integrals are given by:
                    \begin{equation}\label{eq:Coulomb and exchange integrals}.
                        \begin{aligned}
                            J_{ij} = \displaystyle\int \int |\psi_i|^2 \frac{1}{r_{ij}} |\psi_j|^2 d\,\mbf{r}_i\, d\,\mbf{r}_j\\
                            K_{ij} = \displaystyle\int \int \psi_i \psi_j \frac{1}{r_{ij}} \psi_j \psi_i d\,\mbf{r}_i\, d\,\mbf{r}_j
                        \end{aligned}
                    \end{equation}
                     
                \item Obtain new density matrix $\mbf{P}^{(1)}$.
                \item Repeat steps 3. and 4. until convergence.
            \end{enumerate}

        \subsection{Basis Sets and Molecular Orbital Theory}

            HF SCF theory approximated the electron correlation effects as an average repulsive potential that each electron experiences and involved the use of different basis sets. The HF limit is defined as the case when the number of basis functions used in the basis set $\to \infty$. The amount of computational resources required for a practical calculation at the HF limit is extremely large. Therefore the choice of the basis set becomes important and there are three main guidelines to follow:
            \begin{enumerate}
               \item Computational complexity increases with increase in the number of basis functions and so, ideally this number should be as low as possible.
               \item The type of functions used should be in such a way that they facilitate easy evaluation of the four index integrals (Eq. \eqref{eq:one electron Fock matrix elements}). Hence, a large number of easily integrable basis functions might be preferred over a small number of difficult-to-integrate basis functions.
               \item The shape of the functions chosen should make some chemical sense, i.e., the amplitude of the function should be high in places where the probability density of finding the electron would be high and vice-versa.
            \end{enumerate}

            Considering the above mentioned factors, the STOs are rather unfavorable because they lead to four index integrals that are not easily integrable. To overcome this computational problem, Gaussian Type Orbitals (GTOs) were introduced that exhibited a quicker radial decay than their STO counterparts. Although computationally convenient, because of the alterations to the shape brought about by using a different radial decay function, GTOs were seldom used directly as the basis functions in calculations. Also, since GTOs don't exhibit radial nodal behavior, using them one would not be able to mimic, for instance, the 2s orbital which should be negative near the origin and positive beyond a certain distance. To solve these problems, a linear combination of the GTOs were used to obtain basis functions that resembled the STOs as closely as possible. Such basis sets were known as 'contracted' basis sets and the original Gaussians used were known as the 'primitive' Gaussians. For instance:
            \begin{equation}\label{eq:contracted}
               \varphi(x, y, z; {\alpha}, i, j, k) = \displaystyle\sum_{a = 1}^M c_a \phi(x, y, z; \alpha_a, i , j, k)
            \end{equation}
            where $M$ is the number of Gaussians used in the linear combination, and the coefficients $c$ are chosen to optimize the shape of the basis function sum and ensure normalization.

            After performing various calculations, Hehre et al. \cite{Hehre1969} observed that using $M = 3$ primitive Gaussians was the optimum choice in terms of speed and accuracy when comparing to calculations using STOs. Since this is very small as compared to the HF limit, one way to add more flexibility to the basis set would be 'decontract' the basis functions. In other words, keeping the basis set same, we now construct more basis functions for each AO which would result in an increase in size of the secular equation (Eq. \eqref{eq:secular}). Accordingly, using only one basis function per AO is known as 'single-$\zeta$' basis, using two basis functions per AO is known as 'double-$\zeta$' basis and so on. The advantage of this scheme is that using larger and larger basis sets leads us to the HF limit. Since core orbitals tend to be less affected than the valence orbitals during chemical bonding, the 'decontracting' scheme is done more to the valence orbitals than to the core giving rise to 'split-valence' or 'valence-multiple-$\zeta$' basis sets.

            All basis sets considered until now, have comprised functions that are centered on the atoms. The use of such atom centered AOs to describe a molecule with multiple nuclei located at different positions could lead to erroneous results calculated even at near HF limit (for instance, HF calculations predict that a planar structure for NH$_3$ has the lowest energy). To avoid this behavior and to allow more flexibility to the MOs, polarization functions were introduced in the basis sets. It was also observed that there is a rough equality between each decontraction step for the valence electrons and adding one new set of polarization functions, including a new set of higher angular momentum.

            In addition to using polarization functions, diffuse functions are also used leading to what are known as 'augmented' basis sets. This is done so as to let the highest energy MOs, weakly bonded atoms and similar cases be more flexible. In practice, the names of basis sets contains information on what kinds of functions were used in their construction. For instance, the 'aug-cc-pVnZ' (read as 'augmented-coupled-cluster- polarizable Valence n-$\zeta$') basis set uses diffuse functions on all atoms, uses coupled-cluster theory (see Sec. \ref{subsubsec:coupled-cluster theory} for more details) for electron correlation, uses polarizable functions with valence-multiple-$\zeta$ basis with Single(n = 1)-/Double(n = 2)-/Triple(n = 3)-/Qudaruple(n = 4)-/5-/6-$\zeta$ basis functions per AO. As it accounts for a variety of phenomena, one can confidently say that using such a basis set with increasing n would lead to the most accurate value at the HF limit for any desired property. To compute this value, one would simply evaluate the desired property for different n values and extrapolate it to the HF limit (n $\to \infty$).

            The procedure of extrapolation, practical implementation issues, the convergence of the HF SCF method and various other computational issues are discussed in much more detail in Chapter 6 of Cramer's book \cite{Cramer} and so, we continue on to the next important topic of 'Electron Correlation' in the following section.

        \subsection{Electron Correlation}\label{subsec:electron correlation}
            HF theory is intrinsically inflexible for some systems because of the use of single SD wavefunctions only. The logical next step would be to use a linear combination of SD wavefunctions. A 'configuration' or a 'Configuration State Function'(CSF) is defined as the molecular spin state and the occupation numbers of the orbitals. For closed-shell singlets CSFs can always be represented as single determinants. For open-shell systems we required two or more determinants to properly represent the CSFs. Consider a system with two degenerate MO. Due to the nature of the SCF process, degenerate MOs that are not occupied do not contribute to the energy. If we perform two different HF SCF calculations using either of the degenerate orbitals, the resulting energies would expected to be near or exactly the same. This is known as non-dynamical correlation as opposed to the dynamical correlation which arises due to the dynamic character of electronic interactions. Therefore, it would be wise to include different combinations of configurations as part of the optimization process, thus leading to Multiconfiguration Self-Consistent Field(MCSCF) theory. The advantage offered by MCSCF theory is that it can handle both multiple configurations as well as the possibility of multiple determinant representation of each of the configurations.

            Complete Active Space(CAS) of a system is defined as all possible arrangements of the valence electrons in the systems among the different permissible orbitals. As one might guess, the CASSCF calculation is computationally expensive due to the presence of multiple factorials even for the smallest of systems. Instead of using CAS, Restricted Active Space (RAS) methods have been suggested where one includes excited states (either singly, doubly, ... ), as an alternative approach to reduce computational effort.

            Full Configuration Interaction (FCI or just CI) involves the possibility of all electrons being arranged in all possible orbitals of the system. It is worth noting that, performing a FCI calculation with an infinite basis set will yield an exact solution to the \Schrodinger{} equation (time-independent, non-relativistic, BO approximation included). Since this is more computationally expensive than the CASSCF calculation even for the smallest systems, it is seldom performed. However, for larger systems we are limited by the use of small basis sets and hence, performing the FCI calculation is somewhat less interesting. Nevertheless, such a calculation can be used as a reference to compare other methods to include electron correlation using the same basis set. Just as in the RAS methods, one can restrict the excited states to when performing the CI calculation. Accordingly the acronyms CIS, CID and CISD mean CI calculations performed with only singly-, doubly and both singly- as well as doubly- excited states. In CI calculations, it is possible to start with either a single HF SD as a reference or a MCSCF determinant as a reference (in which case the calculation is called Multiple Reference Configuration Interaction (MRCI)).

            \subsubsection{Perturbation Theory}
                Since the calculation of eigenfunctions and eigenvalues for an operator may be complicated due to the presence of certain terms in it, it might be possible to compute exact eigenfunctions and eigenvalues for a simplified version of the same operator and use those to achieve the original operator's eigenfunctions and eigenvalues. This can be done by expanding the ground-state eigenfunctions and eigenvalues as Taylor series in $\lambda$ and evaluating the $n^{\rm th}$ order corrections to the original eigenfunctions and eigenvalues. Mathematically,
                \begin{equation}\label{eq:perturbation theory}
                    \mbf{A} = \mbf{A}^{(0)} + \lambda \mbf{V}
                \end{equation}
                where $\mbf{A}^{(0)}$ is the operator for which we can find eigenfunctions, $\mbf{V}$ is the perturbing operator and $\lambda$ is a dimensionless parameter that maps $\mbf{A}^{(0)}$ onto $\mbf{A}$ as it varies from 0 to 1.

                M\o{}ller and Plesset \cite{Moller1934} applied the perturbation theory in which they considered $\mbf{A}$ to be the Hamiltonian operator $\mbf{H}$ and proposed choices for $\mbf{A}^{(0)}$ and $\mbf{V}$. This approached is widely known with the acronym MP$n$ where $n$ is the order of truncation of the perturbation theory. Within the MP approach $\mbf{H}^{(0)}$ is taken to be the sum of one-electron Fock operators (Eq. \eqref{eq:one electron Fock matrix elements}). $\mbf{H}^{(0)}$ and the perturbing operator $\mbf{V}$ are given as:
                \begin{equation}\label{eq:MP elements}
                    \begin{aligned}
                        \mbf{H}^{(0)} &= \displaystyle\sum_{i=1}^N f_i\\
                        \mbf{V} &= \displaystyle\sum_{i=1}^{occ.} \displaystyle\sum_{j > i}^{occ.} \frac{1}{r_{ij}} - \displaystyle\sum_{i}^{occ.} \displaystyle\sum_{j}^{occ.} \left (J_{ij} - \frac{1}{2} K_{ij} \right)
                    \end{aligned}
                \end{equation}
                where $J_{ij}$ and $K_{ij}$ are the same Coulomb and exchange integrals as described in Eq.\eqref{eq:Coulomb and exchange integrals}.

                Note that the perturbing operator $\mbf{V}$ was designed in such a way that it avoids doubly-counting the electronic repulsion and gives us the correct Hamiltonians for all values of $\lambda$. Also, since we are summing over the occupied orbitals, we must be working with the MO basis set rather than the AO one. MP$n$ applied with ground state HF wavefunction is known as single reference MP$n$ and with a ground state MCSCF wavefunction is known as multireference MP$n$.

            \subsubsection{Coupled-Cluster Theory}\label{subsubsec:coupled-cluster theory}
                A more mathematically elegant way of estimating the electron correlation energy is the coupled-cluster(CC) theory \cite{Cizek1966}. The central idea (skipping all the mathematical details) is that the FCI wavefunction can be described as:
                \begin{equation}\label{eq:cc}
                    \begin{aligned}
                        \Psi &= e^\mbf{T} \Psi_{HF}\\
                        \mbf{T} &= \mbf{T}_1 + \mbf{T}_2 + \mbf{T}_3 + \ldots + \mbf{T}_n
                    \end{aligned}
                \end{equation}
                where $\mbf{T}$ is the cluster operator; $n$ is the total number of electrons; $T_i$ operator generates all possible determinants having $i$ excitations from the reference.

                The advantage of using CC theory is that we can express the exponential function as a Taylor series expansion. To explain this better consider CCD(CC theory with only double excitations):
                \begin{equation}\label{eq:ccd}
                    \Psi_{CCD} = \left( 1 + \mbf{T}_2 + \frac{\mbf{T}_2^2}{2!} + \frac{\mbf{T}_2^3}{3!} + \ldots \right) \Psi_{HF}
                \end{equation}
                The term $1 + \mbf{T}_2$ in the r.h.s is exactly the expression we would use for the CID method (described in Sec. \ref{subsec:electron correlation}). However the terms to the right of it enable us to include the possibility of quadruple, hextuple .. excitations just by using the double excitation operator $\mbf{T}_2$. This would not have been possible in the CI method and hence CC theory is considered size consistent. Based on different cluster operators used, CCS, CCD, CCSD, CCSD(T) and many such calculations have been performed to obtain really accurate \PESs.

                This concludes the introduction to \abinitio{} potentials and the different methodologies used to construct \PESs. Note that a lot of mathematical details and technical insights have been skipped in the above sections, the understanding of which requires further reading than what is mentioned here. That being said, the rest of this dissertation is organized as follows: Chapter 2 provides detailed information of the existing as well as novel methods, algorithms and techniques to compute quantum virial coefficients; Chapters 3 through 7 are each dedicated for a particular system (helium, hydrogen, nitrogen, oxygen and water respectively) and include motivation, recent developments, computational details, virial coefficient results and discussion; Chapter 8 contains concluding remarks and future direction of work including some of the interesting challenges that are yet to be tackled.
